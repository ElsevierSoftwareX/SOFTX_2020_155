diff -uNr linux-3.0/arch/x86/kernel/smpboot.c linux-3.0-cs/arch/x86/kernel/smpboot.c
--- linux-3.0/arch/x86/kernel/smpboot.c	2011-07-22 04:17:23.000000000 +0200
+++ linux-3.0-cs/arch/x86/kernel/smpboot.c	2011-08-03 11:34:39.565642221 +0200
@@ -1316,6 +1316,21 @@
 	pr_err("CPU %u didn't die...\n", cpu);
 }
 
+static DEFINE_PER_CPU(void (*)(void), fe_code);
+
+
+int is_cpu_taken_by_rcg_model(unsigned int cpu) {
+        return 0 != per_cpu(fe_code, cpu);
+}
+EXPORT_SYMBOL(is_cpu_taken_by_rcg_model);
+
+void set_fe_code_idle(void (*ptr)(void), unsigned int cpu) {
+       per_cpu(fe_code, cpu) = ptr;
+}
+
+EXPORT_SYMBOL(set_fe_code_idle);
+
+
 void play_dead_common(void)
 {
 	idle_task_exit();
@@ -1330,6 +1339,10 @@
 	 * With physical CPU hotplug, we should halt the cpu
 	 */
 	local_irq_disable();
+        if (per_cpu(fe_code, smp_processor_id())) {
+	       // Execute front-end code
+	       (*per_cpu(fe_code, smp_processor_id()))();
+	}
 }
 
 /*
diff -uNr linux-3.0/include/linux/kernel.h linux-3.0-cs/include/linux/kernel.h
--- linux-3.0/include/linux/kernel.h	2011-07-22 04:17:23.000000000 +0200
+++ linux-3.0-cs/include/linux/kernel.h	2011-08-03 11:41:39.561822938 +0200
@@ -243,6 +243,12 @@
 	return kstrtoint(s, base, res);
 }
 
+asmlinkage int vprintkl(const char *fmt, va_list args)
+	__attribute__ ((format (printf, 1, 0)));
+asmlinkage int printkl(const char * fmt, ...)
+	__attribute__ ((format (printf, 1, 2))) __cold;
+ 
+
 int __must_check kstrtou16(const char *s, unsigned int base, u16 *res);
 int __must_check kstrtos16(const char *s, unsigned int base, s16 *res);
 int __must_check kstrtou8(const char *s, unsigned int base, u8 *res);
diff -uNr linux-3.0/kernel/cpu.c linux-3.0-cs/kernel/cpu.c
--- linux-3.0/kernel/cpu.c	2011-07-22 04:17:23.000000000 +0200
+++ linux-3.0-cs/kernel/cpu.c	2011-08-03 11:34:39.690634039 +0200
@@ -380,6 +380,8 @@
 	return err;
 }
 
+EXPORT_SYMBOL(cpu_up);
+
 #ifdef CONFIG_PM_SLEEP_SMP
 static cpumask_var_t frozen_cpus;
 
diff -uNr linux-3.0/kernel/printk.c linux-3.0-cs/kernel/printk.c
--- linux-3.0/kernel/printk.c	2011-07-22 04:17:23.000000000 +0200
+++ linux-3.0-cs/kernel/printk.c	2011-08-03 11:34:39.708633518 +0200
@@ -753,6 +753,18 @@
 	return r;
 }
 
+asmlinkage int printkl(const char *fmt, ...)
+{
+	va_list args;
+	int r;
+
+	va_start(args, fmt);
+	r = vprintkl(fmt, args);
+	va_end(args);
+
+	return r;
+}
+
 /* cpu currently holding logbuf_lock */
 static volatile unsigned int printk_cpu = UINT_MAX;
 
@@ -808,6 +820,7 @@
 static int recursion_bug;
 static int new_text_line = 1;
 static char printk_buf[1024];
+static char printkl_buf[1024];
 
 int printk_delay_msec __read_mostly;
 
@@ -963,8 +976,148 @@
 	preempt_enable();
 	return printed_len;
 }
+
+asmlinkage int vprintkl(const char *fmt, va_list args)
+{
+	int printed_len = 0;
+	int current_log_level = default_message_loglevel;
+	unsigned long flags;
+	int this_cpu;
+	char *p;
+
+#if 0
+	boot_delay_msec();
+	printk_delay();
+
+	preempt_disable();
+	/* This stops the holder of console_sem just where we want him */
+	raw_local_irq_save(flags);
+	this_cpu = smp_processor_id();
+
+	/*
+	 * Ouch, printk recursed into itself!
+	 */
+	if (unlikely(printk_cpu == this_cpu)) {
+		/*
+		 * If a crash is occurring during printk() on this CPU,
+		 * then try to get the crash message out but make sure
+		 * we can't deadlock. Otherwise just return to avoid the
+		 * recursion and return - but flag the recursion so that
+		 * it can be printed at the next appropriate moment:
+		 */
+		if (!oops_in_progress) {
+			recursion_bug = 1;
+			goto out_restore_irqs;
+		}
+		zap_locks();
+	}
+#endif
+
+	//lockdep_off();
+	spin_lock(&logbuf_lock);
+	//printk_cpu = this_cpu;
+
+#if 0
+	if (recursion_bug) {
+		recursion_bug = 0;
+		strcpy(printk_buf, recursion_bug_msg);
+		printed_len = strlen(recursion_bug_msg);
+	}
+#endif
+	/* Emit the output into the temporary buffer */
+	printed_len += vscnprintf(printkl_buf + printed_len,
+				  sizeof(printkl_buf) - printed_len, fmt, args);
+
+
+	p = printkl_buf;
+
+	/* Do we have a loglevel in the string? */
+	if (p[0] == '<') {
+		unsigned char c = p[1];
+		if (c && p[2] == '>') {
+			switch (c) {
+			case '0' ... '7': /* loglevel */
+				current_log_level = c - '0';
+			/* Fallthrough - make sure we're on a new line */
+			case 'd': /* KERN_DEFAULT */
+				if (!new_text_line) {
+					emit_log_char('\n');
+					new_text_line = 1;
+				}
+			/* Fallthrough - skip the loglevel */
+			case 'c': /* KERN_CONT */
+				p += 3;
+				break;
+			}
+		}
+	}
+
+	/*
+	 * Copy the output into log_buf.  If the caller didn't provide
+	 * appropriate log level tags, we insert them here
+	 */
+	for ( ; *p; p++) {
+		if (new_text_line) {
+			/* Always output the token */
+			emit_log_char('<');
+			emit_log_char(current_log_level + '0');
+			emit_log_char('>');
+			printed_len += 3;
+			new_text_line = 0;
+
+			if (printk_time) {
+				/* Follow the token with the time */
+				char tbuf[50], *tp;
+				unsigned tlen;
+				unsigned long long t;
+				unsigned long nanosec_rem;
+
+				t = cpu_clock(0);
+				nanosec_rem = do_div(t, 1000000000);
+				tlen = sprintf(tbuf, "[%5lu.%06lu] ",
+						(unsigned long) t,
+						nanosec_rem / 1000);
+
+				for (tp = tbuf; tp < tbuf + tlen; tp++)
+					emit_log_char(*tp);
+				printed_len += tlen;
+			}
+			if (!*p)
+				break;
+		}
+
+		emit_log_char(*p);
+		if (*p == '\n')
+			new_text_line = 1;
+	}
+
+#if 0
+	/*
+	 * Try to acquire and then immediately release the
+	 * console semaphore. The release will do all the
+	 * actual magic (print out buffers, wake up klogd,
+	 * etc). 
+	 *
+	 * The acquire_console_semaphore_for_printk() function
+	 * will release 'logbuf_lock' regardless of whether it
+	 * actually gets the semaphore or not.
+	 */
+	if (acquire_console_semaphore_for_printk(this_cpu))
+		release_console_sem();
+
+	lockdep_on();
+out_restore_irqs:
+	raw_local_irq_restore(flags);
+
+	preempt_enable();
+#endif
+	spin_unlock(&logbuf_lock);
+	return printed_len;
+}
 EXPORT_SYMBOL(printk);
+EXPORT_SYMBOL(printkl);
 EXPORT_SYMBOL(vprintk);
+EXPORT_SYMBOL(vprintkl);
 
 #else
 
